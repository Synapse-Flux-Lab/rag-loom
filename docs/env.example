# RAG Platform Kit - Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# BASIC CONFIGURATION
# =============================================================================
PROJECT_NAME="RAG Microservice"
VERSION="1.0.0"
API_V1_STR="/api/v1"

# =============================================================================
# CHUNKING SETTINGS
# =============================================================================
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_FILE_SIZE=10485760  # 10MB in bytes

# =============================================================================
# VECTOR DATABASE CONFIGURATION
# =============================================================================
# Choose one: chroma, qdrant, redis
VECTOR_STORE_TYPE=chroma

# ChromaDB (Default - Local file-based)
CHROMA_PATH=./chroma_db

# Qdrant (Cloud or local)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=your_qdrant_api_key_here

# Redis
REDIS_URL=redis://localhost:6379

# =============================================================================
# EMBEDDING MODEL CONFIGURATION
# =============================================================================
# Sentence Transformers model (default)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIM=384

# Alternative models you can use:
# EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
# EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
# EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L12-v2

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Choose one: openai, cohere, huggingface
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-3.5-turbo
# Alternative models: gpt-4, gpt-3.5-turbo-16k, gpt-4-turbo

# Cohere Configuration
COHERE_API_KEY=your_cohere_api_key_here
COHERE_MODEL=command-xlarge
# Alternative models: command, command-light, command-nightly

# HuggingFace Configuration
HUGGINGFACE_MODEL=google/flan-t5-large
# Alternative models: microsoft/DialoGPT-medium, facebook/opt-350m

# =============================================================================
# RETRIEVAL SETTINGS
# =============================================================================
TOP_K=5
SIMILARITY_THRESHOLD=0.7

# =============================================================================
# CORS SETTINGS
# =============================================================================
# Add your frontend URLs here
CORS_ORIGINS=["http://localhost:3000", "http://127.0.0.1:3000"]

# =============================================================================
# LOGGING AND MONITORING
# =============================================================================
LOG_LEVEL=INFO
ENABLE_METRICS=true
ENABLE_TRACING=false

# =============================================================================
# SECURITY SETTINGS
# =============================================================================
# Enable authentication (set to true in production)
ENABLE_AUTH=false
SECRET_KEY=your_secret_key_here
ACCESS_TOKEN_EXPIRE_MINUTES=30

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================
WORKER_PROCESSES=1
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT=300

# =============================================================================
# STORAGE SETTINGS
# =============================================================================
UPLOAD_DIR=./uploads
PROCESSED_DIR=./processed
CACHE_DIR=./cache

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================
DEBUG=false
RELOAD=true
ENVIRONMENT=development

# =============================================================================
# EXAMPLE CONFIGURATIONS
# =============================================================================

# For OpenAI + ChromaDB (Recommended for development):
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-...
# VECTOR_STORE_TYPE=chroma
# CHROMA_PATH=./chroma_db

# For Cohere + Qdrant (Production ready):
# LLM_PROVIDER=cohere
# COHERE_API_KEY=...
# VECTOR_STORE_TYPE=qdrant
# QDRANT_URL=https://your-cluster.qdrant.io
# QDRANT_API_KEY=...

# For HuggingFace + Redis (Self-hosted):
# LLM_PROVIDER=huggingface
# VECTOR_STORE_TYPE=redis
# REDIS_URL=redis://localhost:6379
